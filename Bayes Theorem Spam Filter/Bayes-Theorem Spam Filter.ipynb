{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539172c7-a31d-4ae6-80e3-0e997be75b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e282c05-89d1-4e0e-baf3-be4f62e64e0c",
   "metadata": {},
   "source": [
    "# Explore and clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79b497-bb08-43b5-8f18-42d7a0c1981a",
   "metadata": {},
   "source": [
    "    1. (2pt) Load the lingspam-emails.csv.bz2 dataset. \n",
    "    Browse a handful of emails, both spam and non-spam ones, to see what kind of text we are working with here.\n",
    "    Hint: check out textwrap module to print long strings on multiple lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e913ba6a-e98f-47b8-8ede-62dea8d1ddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>False</td>\n",
       "      <td>8-1149msg0.txt</td>\n",
       "      <td>Subject: toc for linguist list  dear sirs , pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>False</td>\n",
       "      <td>6-474msg2.txt</td>\n",
       "      <td>Subject: [ n + v ] verbal compounding  content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>False</td>\n",
       "      <td>5-1326msg1.txt</td>\n",
       "      <td>Subject:   a n n o u n c i n g cunyforum 18 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>False</td>\n",
       "      <td>5-1462msg1.txt</td>\n",
       "      <td>Subject: re : 5 . 1448 comparative method  the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>False</td>\n",
       "      <td>9-288msg1.txt</td>\n",
       "      <td>Subject: mental lexicon  first international c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam           files                                            message\n",
       "1394  False  8-1149msg0.txt  Subject: toc for linguist list  dear sirs , pr...\n",
       "2063  False   6-474msg2.txt  Subject: [ n + v ] verbal compounding  content...\n",
       "614   False  5-1326msg1.txt  Subject:   a n n o u n c i n g cunyforum 18 , ...\n",
       "727   False  5-1462msg1.txt  Subject: re : 5 . 1448 comparative method  the...\n",
       "2215  False   9-288msg1.txt  Subject: mental lexicon  first international c..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "email_df = pd.read_csv('/home/jovyan/INFO371PS/Data/lingspam-emails.csv', sep = \"\\t\")\n",
    "# Browse a handful of emails\n",
    "email_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df509946-ba20-4911-93af-e8077cb471f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Subject: dear website operator  hi , i thought this could help your',\n",
       "  'success . feel free to call me with any questions . sincerely ,',\n",
       "  'jennifer powers 904-441 - 8080 env associates you will never receive a',\n",
       "  'message from me again . * * * first time ever offered ! * * * keep',\n",
       "  'your prospect pipeline - tm filled ! disappointed with traditional',\n",
       "  \"marketing ? maybe it 's time to consider ' business to business '\",\n",
       "  'direct e - mail . forget the \" get rich quick \" schemes and $ 395 +',\n",
       "  'software . forget the \" 60 million \" address cd \\'s that are filled',\n",
       "  'with duplicates and even invalid , \" generated \" addresses , hidden in',\n",
       "  'many different files that rarely add up to even a million prospects',\n",
       "  'which are still unqualified . over 90 % are private personal addresses',\n",
       "  'of people who do not want to be invaded and unless you have duplicate',\n",
       "  'filtering software , you would be mailing many of them multiple times',\n",
       "  ', with the same message ! no wonder they call it spam . you should',\n",
       "  'respect their privacy . prospect pipeline - tm gets you started with',\n",
       "  'the contact e-mail addresses from each of 100 , 000 unique commercial',\n",
       "  'web sites ( e . g . www . mysite . com ) and a free 5 day trial of e -',\n",
       "  'mail pump : software that does what every business needs done - - it',\n",
       "  \"keeps a pipeline of prospects coming . maybe it 's time you filled\",\n",
       "  'your pipeline ? prospect pipeline is the most reasonable marketing /',\n",
       "  \"announcement tool you ' ll ever find at $ 49 . 95 ( + s&h ) . you can\",\n",
       "  'continue to receive a fresh cd ( 100 , 000 new commercial addresses )',\n",
       "  'each month thereafter , at a 20 % discount . we can even deliver them',\n",
       "  'to you automatically ! prospect pipeline - tm addresses are contact',\n",
       "  \"addresses from commercial web sites ( 100 % ' . com ' ) . a commercial\",\n",
       "  'domain ( . com ) is a business by definition and business people love',\n",
       "  'to do business . you know the value of qualified prospects and how',\n",
       "  \"much time and money you can waste if they ' re not . this is an\",\n",
       "  'extremely reasonable offer ! get down to business today . stop waiting',\n",
       "  'for prospects to find you . prospect pipeline - tm business to',\n",
       "  'business package includes : 100 , 000 highly refined ( no duplicates )',\n",
       "  'commercial contact e - mail addresses in plain text files ready for',\n",
       "  \"mailing . a free , fully functional , 5 day trial of ' e - mail pump ,\",\n",
       "  \"' the latest in direct mail software technology . start prospecting\",\n",
       "  \"immediately ! e - mail pump includes a built in ' instant '\",\n",
       "  \"registration process via the internet . it 's also priced reasonably\",\n",
       "  'at $ 49 . 95 , should you decide to register . if you have any further',\n",
       "  'questions or to place an order by phone , please do not hesitate to',\n",
       "  'call us at : 904-441 - 8080 business hours are monday - saturday 9 :',\n",
       "  '00 am - 9 : 00 pm . to order by fax or postal mail , simply print out',\n",
       "  'the order form below and fax or mail it to our office today . * * * *',\n",
       "  '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *',\n",
       "  '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *',\n",
       "  'we accept us checks by fax , telephone and postal mail . money orders',\n",
       "  'in us dollars drawn on us or canadian banks only , are accepted by',\n",
       "  'postal mail . * * * * * * * * * * * * * * * * * * * * * * * * * * * *',\n",
       "  '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *',\n",
       "  '* * * * * * * * * * * - - - - - - - - - - - - - - - - - - - - - - - -',\n",
       "  '- - - - - order form - - - - - - - - - - - - - - - - - - - - - - - - -',\n",
       "  '- - - - - - - - - - - env associates - voice telephone : 904-441 -',\n",
       "  '8080 business hours are monday - saturday 9 : 00 am - 9 : 00 pm .',\n",
       "  'complete this form and follow the fax instructions at the bottom . all',\n",
       "  'orders are sent us postal service 3 day priority mail or global',\n",
       "  \"priority mail outside of the us . _ _ _ _ _ yes ! please send me the '\",\n",
       "  \"prospect pipeline - tm ' cd-rom of 100 , 000 fresh , new , commercial\",\n",
       "  'addresses and free - 5 day trial of e - mail pump for only $ 49 . 95 (',\n",
       "  'us dollars ) name _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ company',\n",
       "  'name _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ address _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ address _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ city , state , zip _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ country _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ phone number',\n",
       "  '( s ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ fax number _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  'e-mail address _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 2nd e-mail address _ _ _ _ _ _ _ _',\n",
       "  '_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ *',\n",
       "  'please select the appropriate shipping for your location and make your',\n",
       "  'check payable for the respective total . . . _ _ _ _ i am in the',\n",
       "  'united states , so i will add $ 3 . 00 for us postal priority mail for',\n",
       "  'a total of $ 52 . 95 ( us dollars ) . _ _ _ _ i am in canada , so i',\n",
       "  'will add $ 6 . 95 for global priority mail for a total of $ 56 . 90 (',\n",
       "  'us dollars ) . _ _ _ _ i am outside the us and canada , so i will add',\n",
       "  '$ 12 . 00 for global priority mail for a total of $ 61 . 95 ( us',\n",
       "  'dollars ) . - - - - - - - - - - - - - - - - - - - - - - - - - - - - -',\n",
       "  '- - - - * * * 24 hour ordering by fax * * * - - - - - - - - - - - - -',\n",
       "  '- - - - - - - - - - - - - - - - - - - - 1 . print this order form 2 .',\n",
       "  'paste or tape your check here 3 . be sure the above form is complete 4',\n",
       "  '. fax to 1-904 - 441-6481 ( 24 hours , 7 days a week ) - - - - - - - -',\n",
       "  '- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -',\n",
       "  '- - - - - - - - - - - - - - - - - - - - - - - - - - - - you need not',\n",
       "  'mail the original check when using check - by - fax . our banking',\n",
       "  'software drafts a special check , with the exact information from your',\n",
       "  'original . orders are shipped at the time funds clear . if you feel',\n",
       "  'uncomfortable with check - by - fax or check - by - phone payment ,',\n",
       "  'send this form with your check or money order to : env associates 171',\n",
       "  'east granada boulevard ormond beach , florida 32176 904-441 - 8080',\n",
       "  'voice 904-441 - 6481 fax * - - - - - - - - - - - - - - - - - - - - - -',\n",
       "  '- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -',\n",
       "  '- - - - - - - - - - - - - - -'],\n",
       " ['Subject: shenandoah language and linguistics society  the shenandoah',\n",
       "  'language and linguistics society symposium is issuing a call for',\n",
       "  'papers for their upcoming symposium to be held at the southern',\n",
       "  'virginia college campus in buena vista , virginia . the conference',\n",
       "  'will be held on march 25-26 , 1999 . topics the conference welcomes',\n",
       "  'papers treating a variety of topics in language and linguistics . this',\n",
       "  'includes not only papers treating topics within linguistic disciplines',\n",
       "  'such as phonology , morphology , syntax , semantics , pragmatics ,',\n",
       "  'sociolinguistics , historical linguistics , and applied linguistics ,',\n",
       "  'but also interdisciplinary presentations that involve language',\n",
       "  'analysis . speakers the keynote speaker is professor william eggington',\n",
       "  ', professor of english language and linguistics at brigham young',\n",
       "  'university . professor eggington specializes in language - in -',\n",
       "  'education policy and general language planning . his most recent book',\n",
       "  'is entitled the sociopolitics of english language teaching . his',\n",
       "  'keynote address is entitled \" linguistic predictors of academic',\n",
       "  'achievement . \" the featured speaker will be professor terry blodgett',\n",
       "  ', professor of german at southern utah university . he is currently',\n",
       "  'preparing a four-volume book entitled israel : the migrations .',\n",
       "  'professor blodgett will be speaking on \" the four sound shifts which',\n",
       "  'reveal israel \\'s four migrations . \" submissions mail your abstracts (',\n",
       "  'see accompanying submission form ) to professor dallin d . oaks ,',\n",
       "  'department of arts and humanities , southern virginia college . buena',\n",
       "  'vista , virginia 24416 . submissions may be faxed to ( 540 ) 261-8451',\n",
       "  '. please do not send any submissions by electronic mail . the deadline',\n",
       "  'for receiving abstracts will be january 25 , 1999 . for further',\n",
       "  'information contact professor dallin d . oaks at ( 540 ) 261-4117 . or',\n",
       "  'e-mail him at doaks @ southernvirginia . edu submission form 1 ) name',\n",
       "  '( as you wish to appear in the program ) : 2 ) university or',\n",
       "  'institutional affiliation : 3 ) title of presentation : 4 ) address at',\n",
       "  'which you can be reached ( please include phone numbers as well as an',\n",
       "  'e-mail address if you have one ) : 5 ) please indicate with a check',\n",
       "  'mark the general area of language analysis or linguistics that most',\n",
       "  'closely corresponds to the topic of your presentation : phonetics or',\n",
       "  'phonology _ _ _ _ _ historical linguistics _ _ _ _ _ morphology _ _ _',\n",
       "  '_ _ psycholinguistics or language acquisition _ _ _ _ _ syntax _ _ _ _',\n",
       "  '_ language pedagogy _ _ _ _ _ semantics or pragmatics _ _ _ _ _',\n",
       "  'language and literary analysis _ _ _ _ _ discourse analysis _ _ _ _ _',\n",
       "  'names and naming _ _ _ _ _ language varieties _ _ _ _ _ language and',\n",
       "  'computers _ _ _ _ _ other ( please specify ) _ _ _ _ _ 6 ) please',\n",
       "  'indicate the length of time you would like for your presentation .',\n",
       "  'priority in selection will go to the standard presentation time of 20',\n",
       "  'minutes ( with an additional 5 minutes for questions ) . 20 - minute',\n",
       "  'presentation _ _ _ _ _ 40 - minute presentation _ _ _ _ _ 60 - minute',\n",
       "  'presentation _ _ _ _ _ 7 ) attach a 250 word abstract that describes',\n",
       "  'the presentation you would like to make .'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Browse 2 emails, can't do more, too long to display\n",
    "textwrap.wrap(text = email_df.iloc[1140].message), textwrap.wrap(text = email_df.iloc[2127].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa1b9d-8155-42f6-85af-666547fcf49f",
   "metadata": {},
   "source": [
    "    2. (3pt) Ensure the data is clean: remove all cases with missing spam and empty message field. We do not care about the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dbbcfe-16ce-49bd-8279-3e5453399bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2893 entries, 0 to 2892\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   spam     2893 non-null   bool  \n",
      " 1   files    2893 non-null   object\n",
      " 2   message  2893 non-null   object\n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 70.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop the NA values and print basic information\n",
    "email_df = email_df.dropna(subset=['spam', 'message'])\n",
    "email_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a547c-8024-4ba5-bd5c-4930e628eced",
   "metadata": {},
   "source": [
    "# Create Document-term matrix (DTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7157759-76bb-4969-9954-a45cd8e8c41e",
   "metadata": {},
   "source": [
    "    1. (2pt) Choose ∼10 words which might be good to distinguish between spam/non-spam. Use these four: viagra, deadline, million, and and. Choose more words yourself (you may want to return here and reconsider your choice later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb4a6fa-1b42-4bb0-ac2b-916aa9a1481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a list of 10 words\n",
    "list_of_words = ['viagra', 'deadline', 'million', 'and', 'money', 'bank', 'support', 'desperate', 'donation', 'congratulations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec6b34a-5929-4c62-a1f5-b83b533cc1ee",
   "metadata": {},
   "source": [
    "    2. (10pt) Convert your messages into DTM. We do not use the full 60k-words DTM here but only a baby-DTM of the 10 words you picked above. You may add the DTM columns to the original data frame, or keep those in a separate structure.\n",
    "    Creating the DTM involves finding whether the word is contained in the message for all emails in data. You can loop over emails and check each one individually, but pandas string methods make life much easier. You will want to do case-insensitive matching, checking for both upper and lower case. You may consider something like this:\n",
    "    It is more intuitive to work with your data if you convert the logical values returned by contains to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65258c8-c33c-456b-a737-8b468864d8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "      <th>viagra</th>\n",
       "      <th>deadline</th>\n",
       "      <th>million</th>\n",
       "      <th>and</th>\n",
       "      <th>money</th>\n",
       "      <th>bank</th>\n",
       "      <th>support</th>\n",
       "      <th>desperate</th>\n",
       "      <th>donation</th>\n",
       "      <th>congratulations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg1.txt</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np  &gt; date : su...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg2.txt</td>\n",
       "      <td>Subject: s - &gt; np + np  the discussion of s - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg3.txt</td>\n",
       "      <td>Subject: 2 . 882 s - &gt; np np  . . . for me it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3-375msg1.txt</td>\n",
       "      <td>Subject: gent conference  \" for the listserv \"...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg1.txt</td>\n",
       "      <td>Subject: query : causatives in korean  could a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc50.txt</td>\n",
       "      <td>Subject: .  international driver ' s license n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc51.txt</td>\n",
       "      <td>Subject: new on 95 . 8 capital fm  this is new...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc52.txt</td>\n",
       "      <td>Subject: re : new medical technology  company ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc53.txt</td>\n",
       "      <td>Subject: re : your request for an overview  ye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc54.txt</td>\n",
       "      <td>Subject: new on capital fm  this is new at htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam          files                                            message  \\\n",
       "0     False    3-1msg1.txt  Subject: re : 2 . 882 s - > np np  > date : su...   \n",
       "1     False    3-1msg2.txt  Subject: s - > np + np  the discussion of s - ...   \n",
       "2     False    3-1msg3.txt  Subject: 2 . 882 s - > np np  . . . for me it ...   \n",
       "3     False  3-375msg1.txt  Subject: gent conference  \" for the listserv \"...   \n",
       "4     False  3-378msg1.txt  Subject: query : causatives in korean  could a...   \n",
       "...     ...            ...                                                ...   \n",
       "2888   True   spmsgc50.txt  Subject: .  international driver ' s license n...   \n",
       "2889   True   spmsgc51.txt  Subject: new on 95 . 8 capital fm  this is new...   \n",
       "2890   True   spmsgc52.txt  Subject: re : new medical technology  company ...   \n",
       "2891   True   spmsgc53.txt  Subject: re : your request for an overview  ye...   \n",
       "2892   True   spmsgc54.txt  Subject: new on capital fm  this is new at htt...   \n",
       "\n",
       "      viagra  deadline  million  and  money  bank  support  desperate  \\\n",
       "0          0         0        0    1      0     0        1          0   \n",
       "1          0         0        0    0      0     0        0          0   \n",
       "2          0         0        0    0      0     0        0          0   \n",
       "3          0         0        0    1      1     1        0          0   \n",
       "4          0         0        0    1      0     0        0          0   \n",
       "...      ...       ...      ...  ...    ...   ...      ...        ...   \n",
       "2888       0         0        0    1      0     0        0          0   \n",
       "2889       0         0        1    1      0     0        0          0   \n",
       "2890       0         0        0    1      0     0        0          0   \n",
       "2891       0         0        1    1      1     0        0          0   \n",
       "2892       0         0        1    1      0     0        0          0   \n",
       "\n",
       "      donation  congratulations  \n",
       "0            0                0  \n",
       "1            0                0  \n",
       "2            0                0  \n",
       "3            0                0  \n",
       "4            0                0  \n",
       "...        ...              ...  \n",
       "2888         0                0  \n",
       "2889         0                0  \n",
       "2890         0                0  \n",
       "2891         0                0  \n",
       "2892         0                0  \n",
       "\n",
       "[2893 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DTM columns to the original df\n",
    "for w in list_of_words:\n",
    "    email_df[w] = email_df.message.str.lower().str.contains(w) + 0\n",
    "email_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d444e6-f2b4-4f56-a4ac-d8040bc151ad",
   "metadata": {},
   "source": [
    "    3. (3pt) Split your work data (i.e. the DTM) and target (the spam indicator) into training and validation chunks (80/20 is a good split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4988f923-ce94-43d1-a9d2-a50314e4561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "X = email_df[list_of_words]\n",
    "y = email_df.spam*1\n",
    "# Spilit the dataset into training and validation \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df824b80-26da-46d4-9693-2475ccbbc8d4",
   "metadata": {},
   "source": [
    "# Estimate and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f5705-c971-4ed2-ba5d-399c907c8f83",
   "metadata": {},
   "source": [
    "    1. (2pt) Design a scheme for your variable names that describes these probabilities so that a) you understand what they mean; and b) the others (including your grader) will understand those!\n",
    "    Hint: you may get some ideas from the Python notes, Section 2.3 Base Language. The first task is to compute these probabilities. Use only training data for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542967a2-7eba-4831-ae0b-944458f8680a",
   "metadata": {},
   "source": [
    "| Variable Name | Notation                 | Definition                                                          |\n",
    "|---------------|--------------------------|--------------------------------------------------------------------|\n",
    "| Pr_S1         | $$Pr(S = 1)$$            | Probability that the email is spam                               |\n",
    "| Pr_S0         | $$Pr(S = 0)$$            | Probability that the email is non-spam                           |\n",
    "| Pr_W1         | $$Pr(W = 1)$$            | Probability that the the word exist in the email                               |\n",
    "| Pr_W0         | $$Pr(W = 0)$$            | Probability that the the word does not exist in the email                           |\n",
    "| Pr_W1_S1      | $$Pr(W = 1\\\\|S = 1)$$     | Conditional probability that the word is present in spam emails     |\n",
    "| Pr_W1_S0      | $$Pr(W = 1\\\\|S = 0)$$     | Conditional probability that the word is present in non-spam emails |\n",
    "| Pr_S1_W1      | $$Pr(S = 1\\\\|W = 1)$$     | Conditional probability that the email is spam given the condition that the word present in the email    |\n",
    "| Pr_S0_W1      | $$Pr(S = 0\\\\|W = 1)$$     | Conditional probability that the email is not spam given the condition that the word present in the email |\n",
    "| Pr_S1_W0      | $$Pr(S = 1\\\\|W = 0)$$     | Conditional probability that the email is spam given the condition that the word is not present in the email    |\n",
    "| Pr_S0_W0      | $$Pr(S = 0\\\\|W = 0)$$     | Conditional probability that the email is not spam given the condition that the word is not present in the email |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb4991-1eee-4ba6-9889-fc616e2d3024",
   "metadata": {},
   "source": [
    "    2. (4pt) Compute the priors, the unconditional probabilities for an email being spam and non-spam, Pr(category =S)and Pr(category =NS). These probabilities are based on the spam variable alone, not on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdcfab5a-75d7-4953-9cfd-a9430fe17af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable Pr_S1, Pr_S0\n",
    "Pr_S1 = y_train.mean()\n",
    "Pr_S0 = 1 - Pr_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e88d7b1-9989-4889-9e9c-4cab1873b50a",
   "metadata": {},
   "source": [
    "The next tasks involve computing the following probabilities for each word out of the list of 10 you picked above, I recommend to avoid unneccessary complexity and just to write a loop over the words, compute the answers 3–8, and print the word and the corresponding results there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76757468-eae5-4a5a-b2c8-b3922df02ecb",
   "metadata": {},
   "source": [
    "    3. (4pt) For each word w, compute the normalizers, Pr(w=1)and Pr(w=0).\n",
    "    Hint: this is Pr(million =1)=0.0484. But note this value (and the following hints) depends on your random training/validation split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade9f362-007c-4933-95ea-fe0290af63ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(W = 0):\n",
      "viagra             0.999568\n",
      "deadline           0.853500\n",
      "million            0.949870\n",
      "and                0.056180\n",
      "money              0.914866\n",
      "bank               0.939931\n",
      "support            0.896283\n",
      "desperate          0.997839\n",
      "donation           0.999136\n",
      "congratulations    0.997839\n",
      "dtype: float64\n",
      "Pr(W = 1)\n",
      "viagra             0.000432\n",
      "deadline           0.146500\n",
      "million            0.050130\n",
      "and                0.943820\n",
      "money              0.085134\n",
      "bank               0.060069\n",
      "support            0.103717\n",
      "desperate          0.002161\n",
      "donation           0.000864\n",
      "congratulations    0.002161\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# For each word w, compute the normalizers\n",
    "Pr_W1 = X_train.mean()\n",
    "Pr_W0 = 1- Pr_W1\n",
    "# for w in X_train.columns:\n",
    "#     Pr_W1 = X_train[w].mean() \n",
    "#     Pr_W0 = 1 - Pr_W1\n",
    "#     print(w, 'Pr(W = 0):', Pr_W1, 'Pr(W = 1)',Pr_W0)\n",
    "#     Pr_W1_list.append(Pr_W1)\n",
    "#     Pr_W0_list.append(Pr_W0)\n",
    "print('Pr(W = 0):', Pr_W0, sep='\\n')\n",
    "print('Pr(W = 1)', Pr_W1, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d498764-2d15-4f80-88c5-ab95f83dd52a",
   "metadata": {},
   "source": [
    "    4. (7pt) For each word w, compute Pr(w=1|category =S)and Pr(w=1|category =NS). These probabilities are based on both the spam-variable and on the DTM component that corresponds to the word w.\n",
    "    Hint: Pr(million =1|category =S)=0.252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd154ab-ed41-48c4-9ecf-b1e86df6f390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(W = 1|S = 1):\n",
      "viagra             0.002625\n",
      "deadline           0.000000\n",
      "million            0.249344\n",
      "and                0.921260\n",
      "money              0.383202\n",
      "bank               0.165354\n",
      "support            0.125984\n",
      "desperate          0.010499\n",
      "donation           0.002625\n",
      "congratulations    0.007874\n",
      "dtype: float64\n",
      "Pr(W = 1|S = 0):\n",
      "viagra             0.000000\n",
      "deadline           0.175375\n",
      "million            0.010864\n",
      "and                0.948267\n",
      "money              0.026384\n",
      "bank               0.039317\n",
      "support            0.099327\n",
      "desperate          0.000517\n",
      "donation           0.000517\n",
      "congratulations    0.001035\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute Pr(W = 1|S = 1), Pr(W = 1|S = 0) for each w\n",
    "Pr_W1_S1 = np.mean(X_train[y_train == 1], axis=0)\n",
    "Pr_W1_S0 = np.mean(X_train[y_train == 0], axis=0)\n",
    "# for w in X_train.columns:\n",
    "#     Pr_W1_S1 = np.mean(X_train[w][y_train == 1])\n",
    "#     Pr_W1_S0 = np.mean(X_train[w][y_train == 0])\n",
    "#     print(w, 'Pr(W = 1|S = 1):', Pr_W1_S1, ', Pr(W = 1|S = 0):', Pr_W1_S0)\n",
    "#     Pr_W1_S1_list.append(Pr_W1_S1)\n",
    "#     Pr_W1_S0_list.append(Pr_W1_S0)\n",
    "print('Pr(W = 1|S = 1):', Pr_W1_S1, sep='\\n')\n",
    "print('Pr(W = 1|S = 0):', Pr_W1_S0, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cabd06-806c-4169-ada5-588d02f10ca8",
   "metadata": {},
   "source": [
    "    5. (5pt) Finally, compute the probabilities of interest, Pr(category =S|w=1)and Pr(category = S|w=0). Compute this value using Bayes theorem, not directly by counting!\n",
    "    For the check, you may also compute Pr(category =NS|w=1)and Pr(category =NS|w=0)\n",
    "    Hint: Pr(category =S|million =1)=0.843. But note this number depends on your random testing-validation split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3e7b4d-6829-446e-994c-43c531950da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(S = 1|W = 1):\n",
      "viagra             1.000000\n",
      "deadline           0.000000\n",
      "million            0.818966\n",
      "and                0.160714\n",
      "money              0.741117\n",
      "bank               0.453237\n",
      "support            0.200000\n",
      "desperate          0.800000\n",
      "donation           0.500000\n",
      "congratulations    0.600000\n",
      "dtype: float64\n",
      "Pr(S = 1|W = 0):\n",
      "viagra             0.164289\n",
      "deadline           0.192911\n",
      "million            0.130118\n",
      "and                0.230769\n",
      "money              0.111006\n",
      "bank               0.146207\n",
      "support            0.160559\n",
      "desperate          0.163274\n",
      "donation           0.164360\n",
      "congratulations    0.163707\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute Pr_S1_W1, Pr_S1_W0, Pr_S0_W1, Pr_S0_W0 for each word\n",
    "Pr_S1_W1 = (Pr_W1_S1 * Pr_S1) / Pr_W1\n",
    "Pr_S1_W0 = ((1 - Pr_W1_S1) * Pr_S1) / Pr_W0\n",
    "Pr_S0_W1 = 1 - Pr_S1_W1\n",
    "Pr_S0_W0 = 1 - Pr_S1_W0\n",
    "print('Pr(S = 1|W = 1):', Pr_S1_W1, sep='\\n')\n",
    "print('Pr(S = 1|W = 0):', Pr_S1_W0, sep='\\n')\n",
    "# for w in X_train.columns:\n",
    "#     Pr_S1_W1 = (np.mean(X_train[w][y_train == 1]) * Pr_S1) / X_train[w].mean() \n",
    "#     Pr_S1_W0 = ((1 - np.mean(X_train[w][y_train == 1])) * Pr_S1) / (1 - Pr_W1)\n",
    "#     print(w, 'Pr(S = 1|W = 1):', Pr_S1_W1, 'Pr(S = 1|W = 0):', Pr_S1_W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e46b70-16e5-4658-a530-a323ea9af4c4",
   "metadata": {},
   "source": [
    "    6. (6pt) Which of these probabilities have to sum to one? (E.g. Pr(category =1)+Pr(category =0)=1.) Which ones do not? Explain!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c215a9-629a-4382-8871-41cabd6d0e2b",
   "metadata": {},
   "source": [
    "Now we are done with the estimator. Your fitted model is completely described by these probabilities. Let’s now turn to prediction, using your validation data. Note that we are still inside the loop over each word w!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde1cdd-f998-4b93-8d01-b133a0cdde81",
   "metadata": {},
   "source": [
    "As we can see from the table above, the sum of Pr(Category = S|W = 1) and Pr(Category = NS|W = 1) is 1. Also, the sum of Pr(Category = S|W = 0) and Pr(Category = NS|W = 0) is also 1. This is because they are given the same conditions. Both have the condition that the word exists in the email, or both have the condition that the word does not exist in the email. For example, if Pr(Category = S|W = 1) and Pr(Category = NS|W = 1), since they have the same condition, they have to sum up to be 1 since it is either spam or not. \n",
    "\n",
    "On the other hand, if the condition given is not the same, then the probabilities cannot add up to one since they have different conditions. Although, in some extreme situations, there is a highly unlikely situation where they may add up to 1 by chance.\n",
    "\n",
    "In addition, Pr(w = 1) + Pr(w = 0) = 1 and Pr(category = S) + Pr(category = NS) = 1. This is because that this is a binary situation. The email can either be spam or not spam and one specific word can only exist or not exist in an email. That is why they also sum up to be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4f9d30-4691-402a-8e24-460d6aa45555",
   "metadata": {},
   "source": [
    "    7. (8pt) For each email in your validation set, predict whether it is predicted to be spam or non-spam. \n",
    "    Hint: you should check if it contains the word wand use the appropriate probability, Pr(category =S|w=1)or Pr(category =S|w=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db409022-bdc1-40a6-ab58-f9958fcf4b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viagra</th>\n",
       "      <th>deadline</th>\n",
       "      <th>million</th>\n",
       "      <th>and</th>\n",
       "      <th>money</th>\n",
       "      <th>bank</th>\n",
       "      <th>support</th>\n",
       "      <th>desperate</th>\n",
       "      <th>donation</th>\n",
       "      <th>congratulations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      viagra  deadline  million  and  money  bank  support  desperate  \\\n",
       "1442       0         0        0    0      1     0        0          0   \n",
       "2585       0         0        0    0      0     0        0          0   \n",
       "1091       0         0        0    0      0     0        0          0   \n",
       "2002       0         0        0    0      0     0        0          0   \n",
       "579        0         0        0    0      1     0        0          0   \n",
       "...      ...       ...      ...  ...    ...   ...      ...        ...   \n",
       "1267       0         0        0    0      0     0        0          0   \n",
       "751        0         0        0    0      0     0        0          0   \n",
       "818        0         0        0    0      0     0        0          0   \n",
       "346        0         0        0    0      0     0        0          0   \n",
       "1548       0         0        0    0      0     0        0          0   \n",
       "\n",
       "      donation  congratulations  \n",
       "1442         0                0  \n",
       "2585         0                0  \n",
       "1091         0                0  \n",
       "2002         0                0  \n",
       "579          0                0  \n",
       "...        ...              ...  \n",
       "1267         0                0  \n",
       "751          0                0  \n",
       "818          0                0  \n",
       "346          0                0  \n",
       "1548         0                0  \n",
       "\n",
       "[579 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the X_val to avoid warnings\n",
    "prediction = X_val.copy()\n",
    "# Create for loop to predict whether an email is spam or not based on the probabilities\n",
    "for w in prediction.columns:\n",
    "    new = np.where(X_val[w] > 0, Pr_S1_W1[w], Pr_S1_W0[w])\n",
    "    spam = np.where(new > 0.5, 1, 0)\n",
    "    prediction[w] = spam\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17fdd68-82cd-4a0f-84d4-b04b17e5f80a",
   "metadata": {},
   "source": [
    "    8. (5pt) Print the resulting confusion matrix and compute accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "348bd1de-0e7d-415e-bd6a-ee807135194c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viagra\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "deadline\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "million\n",
      "[[476   3]\n",
      " [ 79  21]]\n",
      "Accuracy: 0.8583765112262521\n",
      "Precision: 0.875\n",
      "Recall: 0.21\n",
      "and\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "money\n",
      "[[463  16]\n",
      " [ 66  34]]\n",
      "Accuracy: 0.8583765112262521\n",
      "Precision: 0.68\n",
      "Recall: 0.34\n",
      "bank\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "support\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "desperate\n",
      "[[478   1]\n",
      " [ 99   1]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.5\n",
      "Recall: 0.01\n",
      "donation\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "congratulations\n",
      "[[479   0]\n",
      " [ 98   2]]\n",
      "Accuracy: 0.8307426597582038\n",
      "Precision: 1.0\n",
      "Recall: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Import warnings to ignore the warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Create for loop to create confusion matrix, accuracy, precision, and recall for each word\n",
    "for w in prediction.columns:\n",
    "    cm = confusion_matrix(y_val, prediction[w])\n",
    "    accuracy = accuracy_score(y_val, prediction[w])\n",
    "    precision = precision_score(y_val, prediction[w])\n",
    "    recall = recall_score(y_val, prediction[w])\n",
    "    print(w, cm, sep='\\n')\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de2905-89cc-4f46-a30c-b11a8261955a",
   "metadata": {},
   "source": [
    "    9. (5pt) Which steps above constitute model training? In which steps do you use trained model? What is a trained model in this case? Explain!\n",
    "    Hint: a trained model is all you need to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219f1b8-56eb-41db-879a-3398dfaf2d5e",
   "metadata": {},
   "source": [
    "The steps above that we used to constitute model training was in question 3.2-3.5. In 3.2, we are calculating the probabilities of the categories of spam and non-spam emails (priors). In 3.3, we calculate the probabilities of the word appearing in the dataset or not (normalizers). In 3.4, we calculate probabilities using the prior and normalizers. Then, in 3.5, we used the previous steps to obtain the probabilities of interest so that we can use this trained model for predictions later on. \n",
    "\n",
    "The trained model is then later used in 3.7 and 3.8, where 3.7 used the trained model to predict each email in the validation set, labeling each email to identify if the email is spam or not. We used the predictions of the trained model in 3.7 to construct confusion matrices and compute accuracies, precisions, and recalls of the model in 3.8.\n",
    "\n",
    "The trained model is all we need to make predictions. The trained model, in this case, is the set of these probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c448b02-6aed-4127-ae6f-e38d80d545cd",
   "metadata": {},
   "source": [
    "    10. (4pt) Comment the overall performance of the model–how do accuracy, precision and recall look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ef1f0-e0ae-425f-8835-50480267e2b4",
   "metadata": {},
   "source": [
    "The overall performance of the accuracies is pretty high, with all of them above 80%. Precision varies greatly, going from as low as 0% to as high as 100%. Recall for all of them also varies a bit. However, all of the recall scores are below 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2447ebf8-6aa4-4051-8134-8262ef7ddfba",
   "metadata": {},
   "source": [
    "    11. (8pt) Explain why do you see very low recall while the other indicators do not look that bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abf6e7-8d7c-4fd7-a377-7eed6bf023c6",
   "metadata": {},
   "source": [
    "In the case of high precision and low recall, it is because the predictions are correct when compared to the training data. We see a very low recall because the word predictors can only detect a tiny part of the spam emails in the sample if they have a poor recall. This is not too surprising because spam emails include a lot of different words, but we are just using one word to predict. When the true positives (predicted as 1, actual is 1) are 0, both the recall and precision become 0. This is probably due to the fact of the rather small validation set and the fact that we are using only one predictor to determine whether an email is spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49905032-30f3-433b-9df4-0dd786d698d7",
   "metadata": {},
   "source": [
    "    12. (8pt) Explain why some words work well and others not:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a22d3f-f54d-4006-b7a8-cdbeea89c5e7",
   "metadata": {},
   "source": [
    "    (a) why does “million” improve accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1f4bbc8-14c0-47f4-9fd4-cdcfacbb7980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of emails we have in the data\n",
    "email_df[\"million\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4731b68e-5b84-423a-bb07-37f951258808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of occurances for the word million in all emails\n",
    "email_df[\"million\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff5db8c-0a8a-4357-b336-4c09a17595b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of spam emails that contains the word million\n",
    "email_df[email_df.spam == 1][\"million\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064de1e-4c3b-46ea-89d0-cf3b416cc87a",
   "metadata": {},
   "source": [
    "As we can see from the numbers above, the word million occured in 140 emails, and among those, there are 116 that are spam emails. This means that the word \"million\" occurs in spam emails pretty often. Therefore, when adding it to the model , it does improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37adf40b-0d6b-42c3-bf8f-75eed904b80e",
   "metadata": {},
   "source": [
    "    (b) why does “viagra” not work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7ca3c96-57ed-4061-a9b6-87bb92b49dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of emails we have in the data\n",
    "email_df[\"viagra\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90811258-d3da-4ebb-9d89-c6830d351a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of occurances for the word viagra in all emails\n",
    "email_df[\"viagra\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48db4f3-e6fc-4e9d-9505-b7b932c42174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of spam emails that contains the word viagra\n",
    "email_df[email_df.spam == 1][\"viagra\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240edea8-96b5-455d-a95d-16daa9fa3286",
   "metadata": {},
   "source": [
    "The word \"viagra\" does not improve accuracy because it barely shows up in the emails at all. Out of 2893 emails, there is only one email that conatins the word \"viagra\", it is not a good indication for whether an email is a spam or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d82aa-7fa3-43bb-8e3a-a6b544354fce",
   "metadata": {},
   "source": [
    "    (c) why does “deadline” not work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f603c1f-b290-467a-9433-a84bf1f18012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of occurances for the word deadline in all emails\n",
    "email_df[\"deadline\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c914346-e8cf-401c-8ca9-a8bac3e427cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of spam emails that contains the word deadline\n",
    "email_df[email_df.spam == 1][\"deadline\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ccfd44-2dcb-456b-ac50-fb8c71af1a27",
   "metadata": {},
   "source": [
    "\"Deadline\" does not work because 0 out of the 434 emails that contain the word \"deadline\" is spam. This is not a good indication for whether an email is a spam or not. Deadline is extremely likely to appear in non-spam emails, such as projects in companies or school projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6f4aa-868e-4e49-b4d8-41b65bce90b4",
   "metadata": {},
   "source": [
    "    (d) why does “and” not work?\n",
    "    Hint: You may just see where in which emails these words occur, and how frequently. These are all different reasons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a52de980-8cc7-4db3-a0a8-a11bfce3396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2725"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of occurances for the word and in all emails\n",
    "email_df[\"and\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deff0c87-eb07-4eb3-b2bd-837a39583320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of spam emails that contains the word and\n",
    "email_df[email_df.spam == 1][\"and\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ecd63-4c62-4b45-857c-afdd0b0e452a",
   "metadata": {},
   "source": [
    "The word \"and\" does not work becasue \"and\" is a very commonly used word. It appears that most of the emails in the dataset have the word \"and\". Thus, it is not a good indication to judge whether this email will be spam or not based on the word appearance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db54e0-4b11-4721-a655-1ece5d945e40",
   "metadata": {},
   "source": [
    "    13. (5pt) Add such smoothing to the model. You can either literally add two such lines of data, or alternatively manipulate the way you compute the probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6f8f3-715f-4e3f-8449-463cb1355fba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d61d4ec-fc81-4069-b9ec-cae526e1f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe for smoothing\n",
    "t_emails = pd.DataFrame(X_train, columns = list_of_words)\n",
    "t_emails.insert(loc = 0, column = 'spam', value = y_train.values)\n",
    "# Create four different ghost data\n",
    "t_emails = t_emails.append({\"spam\": 1, \"viagra\": 1, \"deadline\": 1, \"million\": 1, \"and\": 1, \"money\": 1, \"bank\": 1, \"support\": 1, \"desperate\": 1, \"donation\": 1, \"congratulations\": 1}, ignore_index=True)\n",
    "t_emails = t_emails.append({\"spam\": 1, \"viagra\": 0, \"deadline\": 0, \"million\": 0, \"and\": 0, \"money\": 0, \"bank\": 0, \"support\": 0, \"desperate\": 0, \"donation\": 0, \"congratulations\": 0}, ignore_index=True)\n",
    "t_emails = t_emails.append({\"spam\": 0, \"viagra\": 1, \"deadline\": 1, \"million\": 1, \"and\": 1, \"money\": 1, \"bank\": 1, \"support\": 1, \"desperate\": 1, \"donation\": 1, \"congratulations\": 1}, ignore_index=True)\n",
    "t_emails = t_emails.append({\"spam\": 0, \"viagra\": 0, \"deadline\": 0, \"million\": 0, \"and\": 0, \"money\": 0, \"bank\": 0, \"support\": 0, \"desperate\": 0, \"donation\": 0, \"congratulations\": 0}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99232bf-3f41-4ec2-bfb3-a271f8c1ffec",
   "metadata": {},
   "source": [
    "    14. (5pt) Repeat the tasks above: compute the probabilities, do predictions, compute the accuracy, precision, recall for all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91727f80-f4c7-48f3-988a-408c21749042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viagra\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "deadline\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "million\n",
      "[[476   3]\n",
      " [ 79  21]]\n",
      "Accuracy: 0.8583765112262521\n",
      "Precision: 0.875\n",
      "Recall: 0.21\n",
      "and\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "money\n",
      "[[463  16]\n",
      " [ 66  34]]\n",
      "Accuracy: 0.8583765112262521\n",
      "Precision: 0.68\n",
      "Recall: 0.34\n",
      "bank\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "support\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "desperate\n",
      "[[478   1]\n",
      " [ 99   1]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.5\n",
      "Recall: 0.01\n",
      "donation\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy: 0.8272884283246977\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "congratulations\n",
      "[[479   0]\n",
      " [ 98   2]]\n",
      "Accuracy: 0.8307426597582038\n",
      "Precision: 1.0\n",
      "Recall: 0.02\n"
     ]
    }
   ],
   "source": [
    "X_train = t_emails[t_emails.columns.drop('spam')]\n",
    "y_train = t_emails.spam\n",
    "# Create variable Pr_S1, Pr_S0\n",
    "Pr_S1 = y_train.mean()\n",
    "Pr_S0 = 1 - Pr_S1\n",
    "\n",
    "# For each word w, compute the normalizers\n",
    "Pr_W1 = X_train.mean()\n",
    "Pr_W0 = 1- Pr_W1\n",
    "\n",
    "# Compute Pr(W = 1|S = 1), Pr(W = 1|S = 0) for each w\n",
    "Pr_W1_S1 = np.mean(X_train[y_train == 1], axis=0)\n",
    "Pr_W1_S0 = np.mean(X_train[y_train == 0], axis=0)\n",
    "\n",
    "Pr_S1_W1 = (Pr_W1_S1 * Pr_S1) / Pr_W1\n",
    "Pr_S1_W0 = ((1 - Pr_W1_S1) * Pr_S1) / Pr_W0\n",
    "Pr_S0_W1 = 1 - Pr_S1_W1\n",
    "Pr_S0_W0 = 1 - Pr_S1_W0\n",
    "\n",
    "prediction = X_val.copy()\n",
    "\n",
    "for w in prediction.columns:\n",
    "    new = np.where(X_val[w] > 0, Pr_S1_W1[w], Pr_S1_W0[w])\n",
    "    spam = np.where(new > 0.5, 1, 0)\n",
    "    prediction[w] = spam\n",
    "    \n",
    "for w in prediction.columns:\n",
    "    cm = confusion_matrix(y_val, prediction[w])\n",
    "    accuracy = accuracy_score(y_val, prediction[w])\n",
    "    precision = precision_score(y_val, prediction[w])\n",
    "    recall = recall_score(y_val, prediction[w])\n",
    "    print(w, cm, sep='\\n')\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b2717-005a-4a8d-8d3e-fac6509945eb",
   "metadata": {},
   "source": [
    "    15. (4pt) Comment on the results. Does smoothing improve the overall performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87489798-d05d-4806-a22e-d61a917a5175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viagra             0.666667\n",
      "deadline           0.002933\n",
      "million            0.813559\n",
      "and                0.161025\n",
      "money              0.738693\n",
      "bank               0.453901\n",
      "support            0.202479\n",
      "desperate          0.714286\n",
      "donation           0.500000\n",
      "congratulations    0.571429\n",
      "dtype: float64\n",
      "viagra             0.164579\n",
      "deadline           0.193222\n",
      "million            0.130455\n",
      "and                0.234848\n",
      "money              0.111373\n",
      "bank               0.146532\n",
      "support            0.160886\n",
      "desperate          0.163566\n",
      "donation           0.164650\n",
      "congratulations    0.163998\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the new probabilities\n",
    "print(Pr_S1_W1)\n",
    "print(Pr_S1_W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fe219-05d6-4e2b-9344-95d4260e7a29",
   "metadata": {},
   "source": [
    "After adding smoothing to the model, it does not change metrics like the confusion matrix, accuracies, precisions, and recalls (Although it might change it because of the random train_test split, but highly unlikely). Adding smoothing does not improve the overall performance based on observation. However, it does change Pr(S = 1|W = 1) and Pr(S = 1|W = 0) a bit since we added four ghost lines of four different situations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
