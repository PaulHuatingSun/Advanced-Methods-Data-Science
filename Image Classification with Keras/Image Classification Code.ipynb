{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zh_tDcBPBbmn"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/INFO371/language-text-images/train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9LU6FUlHiNb"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/INFO371/language-text-images/validation.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.9.1\n",
      "run interactively from C:\\Users\\pauls\\Desktop\\PS7\n",
      "Load images from language\n",
      "epochs: 10\n",
      "31869 images found\n",
      "data files:\n",
      "                               filename category\n",
      "9530                 dracula_EN-bdc.jpg       EN\n",
      "17477            novel_00010_TH-abj.jpg       TH\n",
      "22994            novel_00082_TH-aao.jpg       TH\n",
      "29656  tolstoy-voina-i-mir-3_RU-arl.jpg       RU\n",
      "28101  tolstoy-voina-i-mir-2_RU-bfh.jpg       RU\n",
      "categories:\n",
      " EN    8442\n",
      "TH    7425\n",
      "RU    6511\n",
      "ZN    5396\n",
      "DA    4095\n",
      "Name: category, dtype: int64\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_51 (Conv2D)          (None, 23, 23, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 23, 23, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 11, 11, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 9, 9, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 9, 9, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 4, 4, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 2, 2, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 5)                 2565      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,259\n",
      "Trainable params: 162,787\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "Found 31869 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "996/996 [==============================] - 40s 39ms/step - loss: 1.5564 - accuracy: 0.2830\n",
      "Epoch 2/10\n",
      "996/996 [==============================] - 39s 39ms/step - loss: 1.4012 - accuracy: 0.4537\n",
      "Epoch 3/10\n",
      "996/996 [==============================] - 37s 38ms/step - loss: 1.2755 - accuracy: 0.5354\n",
      "Epoch 4/10\n",
      "996/996 [==============================] - 38s 38ms/step - loss: 1.1905 - accuracy: 0.5708\n",
      "Epoch 5/10\n",
      "996/996 [==============================] - 38s 39ms/step - loss: 1.1307 - accuracy: 0.6110\n",
      "Epoch 6/10\n",
      "996/996 [==============================] - 38s 38ms/step - loss: 1.0762 - accuracy: 0.6358\n",
      "Epoch 7/10\n",
      "996/996 [==============================] - 40s 40ms/step - loss: 1.0317 - accuracy: 0.6559\n",
      "Epoch 8/10\n",
      "996/996 [==============================] - 39s 39ms/step - loss: 1.0031 - accuracy: 0.6661\n",
      "Epoch 9/10\n",
      "996/996 [==============================] - 39s 39ms/step - loss: 0.9725 - accuracy: 0.6746\n",
      "Epoch 10/10\n",
      "996/996 [==============================] - 40s 40ms/step - loss: 0.9473 - accuracy: 0.6874\n",
      "7967 validation images\n",
      "7967 validation files read from language\\validation\n",
      "Found 7967 validated image filenames.\n",
      " --- Predicting on validation data ---\n",
      "249/249 [==============================] - 7s 28ms/step\n",
      "Predicted probability array shape: (7967, 5)\n",
      "Example:\n",
      " [[0.09273635 0.0291846  0.0599476  0.05612427 0.7620072 ]\n",
      " [0.42559588 0.19640721 0.2086133  0.08990601 0.07947755]\n",
      " [0.11100474 0.7431819  0.08680668 0.03721971 0.021787  ]\n",
      " [0.10212217 0.03717932 0.20072778 0.59460586 0.0653649 ]\n",
      " [0.11088695 0.05225714 0.5260832  0.23234601 0.07842669]]\n",
      "                              filename category  predicted\n",
      "0  aakjaer-samlede-verker-1_DA-aaa.jpg       DA          4\n",
      "1  aakjaer-samlede-verker-1_DA-aad.jpg       DA          0\n",
      "2  aakjaer-samlede-verker-1_DA-aai.jpg       DA          1\n",
      "3  aakjaer-samlede-verker-1_DA-aan.jpg       DA          3\n",
      "4  aakjaer-samlede-verker-1_DA-aau.jpg       DA          2\n",
      "confusion matrix (validation)\n",
      "predicted   DA    EN    RU    TH   ZN\n",
      "category                             \n",
      "DA         193   352    90   340   44\n",
      "EN          85  1921     2    39    3\n",
      "RU          57   197  1126   291   22\n",
      "TH           3    24    57  1802   13\n",
      "ZN          25    44    50   195  992\n",
      "Validation accuracy 0.757374168444835\n",
      "Example wrong results (validation data)\n",
      "                                 filename category predicted\n",
      "1035              chinese-laws_ZN-akj.jpg       ZN        TH\n",
      "598   aakjaer-samlede-verker-3_DA-aqt.jpg       DA        EN\n",
      "285   aakjaer-samlede-verker-2_DA-abh.jpg       DA        TH\n",
      "67    aakjaer-samlede-verker-1_DA-ami.jpg       DA        TH\n",
      "270   aakjaer-samlede-verker-1_DA-bxz.jpg       DA        EN\n",
      "333   aakjaer-samlede-verker-2_DA-alg.jpg       DA        ZN\n",
      "3104                 evolution_EN-cwm.jpg       EN        TH\n",
      "330   aakjaer-samlede-verker-2_DA-aks.jpg       DA        TH\n",
      "3984              liu-shouyuan_ZN-aud.jpg       ZN        TH\n",
      "667   aakjaer-samlede-verker-3_DA-bdy.jpg       DA        EN\n",
      " --- Predicting on training data: ---\n",
      "Found 31869 validated image filenames belonging to 5 classes.\n",
      "996/996 [==============================] - 29s 29ms/step\n",
      "confusion matrix (training)\n",
      "predicted   DA    EN    RU    TH    ZN\n",
      "category                              \n",
      "DA         855  1394   398  1257   191\n",
      "EN         377  7901    21   131    12\n",
      "RU         197   689  4428  1097   100\n",
      "TH          30    94   227  7023    51\n",
      "ZN          76   197   205   748  4170\n",
      "Train accuracy 0.7649126110012865\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## Define image properties:\n",
    "imgDir = \"/content\"\n",
    "targetWidth, targetHeight = 25, 25\n",
    "# targetWidth, targetHeight = 50, 50\n",
    "# targetWidth, targetHeight = 100, 100\n",
    "imageSize = (targetWidth, targetHeight)\n",
    "channels = 1  # color channels\n",
    "\n",
    "## define other constants, including command line argument defaults\n",
    "epochs = 10\n",
    "plot = False  # show plots?\n",
    "\n",
    "## command line arguments\n",
    "# check if this was run as a separate file (not inside notebook)\n",
    "import __main__ as main\n",
    "if hasattr(main, \"__file__\"):\n",
    "    # run as file\n",
    "    print(\"parsing command line arguments\")\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dir\", \"-d\",\n",
    "                        help = \"directory to read images from\",\n",
    "                        default = imgDir)\n",
    "    parser.add_argument(\"--epochs\", \"-e\",\n",
    "                        help = \"how many epochs\",\n",
    "                        default= epochs)\n",
    "    parser.add_argument(\"--plot\", \"-p\",\n",
    "                        action = \"store_true\",\n",
    "                        help = \"plot a few wrong/correct results\")\n",
    "    args = parser.parse_args()\n",
    "    imgDir = args.dir\n",
    "    epochs = int(args.epochs)\n",
    "    plot = args.plot\n",
    "else:\n",
    "    # run as notebook\n",
    "    print(\"run interactively from\", os.getcwd())\n",
    "    imageDir = os.path.join(os.path.expanduser(\"~\"),\n",
    "                            \"data\", \"images\", \"text\", \"language-text-images\")\n",
    "print(\"Load images from\", imgDir)\n",
    "print(\"epochs:\", epochs)\n",
    "\n",
    "## Prepare dataset for training model:\n",
    "filenames = os.listdir(os.path.join(imgDir, \"train\"))\n",
    "print(len(filenames), \"images found\")\n",
    "trainingResults = pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':pd.Series(filenames).str[-10:-8]\n",
    "})\n",
    "\n",
    "# Filtering 3 Languages (training)\n",
    "#trainingResults = trainingResults[(trainingResults.category == 'EN') | (trainingResults.category == 'ZN')|(trainingResults.category == 'TH')]\n",
    "\n",
    "# Using a sample of the training data rather than the whole thing\n",
    "# trainingResults = trainingResults.sample(n=10000, random_state = 1)\n",
    "\n",
    "print(\"data files:\")\n",
    "print(trainingResults.sample(5))\n",
    "nCategories = trainingResults.category.nunique()\n",
    "print(\"categories:\\n\", trainingResults.category.value_counts())\n",
    "## Create model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,\\\n",
    "    MaxPooling2D, AveragePooling2D,\\\n",
    "    Dropout,Flatten,Dense,Activation,\\\n",
    "    BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "## First convolutional layer with 32 filters (kernels)\n",
    "model.add(Conv2D(32,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 input_shape=(targetWidth, targetHeight, channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## 2nd convolutional layer\n",
    "model.add(Conv2D(64,\n",
    "                 kernel_size = 3,\n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## 3rd convolutional layer\n",
    "model.add(Conv2D(128,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=3,\n",
    "#                  activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "## Flatten the image into a string of pixels\n",
    "model.add(Flatten())\n",
    "\n",
    "## Use one final dense layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Output layer with 2 softmax nodes\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.add(Dense(nCategories,\n",
    "                kernel_initializer = initializers.HeNormal(),\n",
    "                activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "## Training and validation data generator:\n",
    "trainingGenerator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ").\\\n",
    "    flow_from_dataframe(trainingResults,\n",
    "                        os.path.join(imgDir, \"train\"),\n",
    "                        x_col='filename', y_col='category',\n",
    "                        target_size=imageSize,\n",
    "                        class_mode='categorical',\n",
    "                        color_mode=\"grayscale\",\n",
    "                        shuffle=True)\n",
    "label_map = trainingGenerator.class_indices\n",
    "## Model Training:\n",
    "history = model.fit(\n",
    "    trainingGenerator,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "## Validation data preparation:\n",
    "validationDir = os.path.join(imgDir, \"validation\")\n",
    "fNames = os.listdir(validationDir)\n",
    "print(len(fNames), \"validation images\")\n",
    "validationResults = pd.DataFrame({\n",
    "    'filename': fNames,\n",
    "    'category': pd.Series(fNames).str[-10:-8]\n",
    "})\n",
    "\n",
    "# Filtering 3 Languages (validation)\n",
    "# validationResults = validationResults[(validationResults.category == 'EN') | (validationResults.category == 'ZN')|(validationResults.category == 'TH')]\n",
    "\n",
    "print(validationResults.shape[0], \"validation files read from\", validationDir)\n",
    "validationGenerator = ImageDataGenerator(rescale=1./255).\\\n",
    "    flow_from_dataframe(validationResults,\n",
    "                        os.path.join(imgDir, \"validation\"),\n",
    "                        x_col='filename',\n",
    "                        class_mode = None,\n",
    "                        target_size = imageSize,\n",
    "                        shuffle = False,\n",
    "                        # do _not_ randomize the order!\n",
    "                        # this would clash with the file name order!\n",
    "                        color_mode=\"grayscale\"\n",
    "    )\n",
    "\n",
    "## Make categorical prediction:\n",
    "print(\" --- Predicting on validation data ---\")\n",
    "phat = model.predict(validationGenerator)\n",
    "print(\"Predicted probability array shape:\", phat.shape)\n",
    "print(\"Example:\\n\", phat[:5])\n",
    "\n",
    "## Convert labels to categories:\n",
    "validationResults['predicted'] = pd.Series(np.argmax(phat, axis=-1), index=validationResults.index)\n",
    "print(validationResults.head())\n",
    "labelMap = {v: k for k, v in label_map.items()}\n",
    "validationResults[\"predicted\"] = validationResults.predicted.replace(labelMap)\n",
    "print(\"confusion matrix (validation)\")\n",
    "print(pd.crosstab(validationResults.category, validationResults.predicted))\n",
    "print(\"Validation accuracy\", np.mean(validationResults.category == validationResults.predicted))\n",
    "\n",
    "## Print and plot misclassified results\n",
    "wrongResults = validationResults[validationResults.predicted != validationResults.category]\n",
    "rows = np.random.choice(wrongResults.index, min(4, wrongResults.shape[0]), replace=False)\n",
    "print(\"Example wrong results (validation data)\")\n",
    "print(wrongResults.sample(min(10, wrongResults.shape[0])))\n",
    "if plot:\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    index = 1\n",
    "    for row in rows:\n",
    "        filename = wrongResults.loc[row, 'filename']\n",
    "        predicted = wrongResults.loc[row, 'predicted']\n",
    "        img = load_img(os.path.join(imgDir, \"validation\", filename), target_size=imageSize)\n",
    "        plt.subplot(4, 2, index)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(filename + \" ({})\".format(predicted))\n",
    "        index += 1\n",
    "    # now show correct results\n",
    "    index = 5\n",
    "    correctResults = validationResults[validationResults.predicted == validationResults.category]\n",
    "    rows = np.random.choice(correctResults.index,\n",
    "                            min(4, correctResults.shape[0]), replace=False)\n",
    "    for row in rows:\n",
    "        filename = correctResults.loc[row, 'filename']\n",
    "        predicted = correctResults.loc[row, 'predicted']\n",
    "        img = load_img(os.path.join(imgDir, \"validation\", filename), target_size=imageSize)\n",
    "        plt.subplot(4, 2, index)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(filename + \" ({})\".format(predicted))\n",
    "        index += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "## Training data predictions.\n",
    "## Do these here to keep the in place for students\n",
    "## \n",
    "print(\" --- Predicting on training data: ---\")\n",
    "# do another generator: the same as training, just w/o shuffle\n",
    "predictTrainGenerator = ImageDataGenerator(rescale=1./255).\\\n",
    "    flow_from_dataframe(trainingResults,\n",
    "                        os.path.join(imgDir, \"train\"),\n",
    "                        x_col='filename', y_col='category',\n",
    "                        target_size=imageSize,\n",
    "                        class_mode='categorical',\n",
    "                        color_mode=\"grayscale\",\n",
    "                        shuffle=False  # do not shuffle!\n",
    "    )\n",
    "phat = model.predict(predictTrainGenerator)\n",
    "trainingResults['predicted'] = pd.Series(np.argmax(phat, axis=-1), index=trainingResults.index)\n",
    "trainingResults[\"predicted\"] = trainingResults.predicted.replace(labelMap)\n",
    "print(\"confusion matrix (training)\")\n",
    "print(pd.crosstab(trainingResults.category, trainingResults.predicted))\n",
    "print(\"Train accuracy\", np.mean(trainingResults.category == trainingResults.predicted))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PS7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
